---
layout: post
title: From Deep Learning of Disentangled Representations to Higher-level Cognition
date: 2018-06-23
categories: [computer science]
tags: [machine learning]

---

## Article Source
* Title: [From Deep Learning of Disentangled Representations to Higher-level Cognition](https://www.youtube.com/watch?v=Yr1mOzC93xs&index=8&list=PLD7HFcN7LXRdF6EcEFmrXGo4pngaR4Z_p)

---


## From Deep Learning of Disentangled Representations to Higher-level Cognition

## Abstract

One of the main challenges for AI remains *unsupervised learning*, at which humans are much better than machines, and which we link to another challenge: bringing deep learning to higher-level cognition. We review earlier work on the notion of learning *disentangled representations* and *deep generative models* and propose research directions towards learning of high-level abstractions. This follows the ambitious objective of disentangling the underlying causal factors explaining the observed data. We argue that in order to efficiently capture these, a learning agent can acquire information by acting in the world, moving our research from traditional deep generative models of given datasets to that of *autonomous learning* or *unsupervised reinforcement learning*. 

We propose two priors which could be used by an agent acting in its environment in order to help discover such high-level disentangled representations of abstract concepts. 

The first one is based on the *discovery of independently controllable factors*, i.e., in jointly learning policies and representations, such that each of these policies can independently control one aspect of the world (a factor of interest) computed by the representation while keeping the other uncontrolled aspects mostly untouched. This idea naturally brings fore the notions of objects (which are controllable), agents (which control objects) and self. 

The second prior is called the *consciousness prior* and is based on the hypothesis that our conscious thoughts are low-dimensional objects with a strong predictive or explanatory power (or are very useful for planning). A conscious thought thus selects a few abstract factors (using the attention mechanism which brings these variables to consciousness) and combines them to make a useful statement or prediction. 

In addition, the concepts brought to consciousness often correspond to words or short phrases and the thought itself can be transformed (in a lossy way) into a brief linguistic expression, like a sentence. Natural language could thus be used as an additional hint about the abstract representations and disentangled factors which humans have discovered to explain their world. Some conscious thoughts also correspond to the kind of small nugget of knowledge (like a fact or a rule) which have been the main building blocks of classical symbolic AI. This, therefore, raises the interesting possibility of addressing some of the objectives of classical symbolic AI focused on higher-level cognition using the deep learning machinery augmented by the architectural elements necessary to implement conscious thinking about disentangled causal factors.


<iframe width="600" height="400" src="https://www.youtube.com/embed/Yr1mOzC93xs" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
