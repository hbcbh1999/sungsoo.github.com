---
layout: post
title: The GAN Zoo
date: 2018-07-02
categories: [computer science]
tags: [machine learning]

---

## Article Source
* Title: [The GAN Zoo](https://deephunt.in/the-gan-zoo-79597dc8c347)

---

The GAN Zoo 
===========

A list of all named GANs! 
-------------------------


![](https://cdn-images-1.medium.com/max/1600/0*ncqqFthh4e9baHxI.jpg)



Pretty painting is always better than a Terminator
Every week, new papers on Generative Adversarial Networks (GAN) are
coming out and it’s hard to keep track of them all, not to mention the
incredibly creative ways in which researchers are naming these GANs! 

You
can read more about GANs in this [Generative Models
post](https://blog.openai.com/generative-models/) by OpenAI or this [overview
tutorial](http://www.kdnuggets.com/2017/01/generative-adversarial-networks-hot-topic-machine-learning.html) in KDNuggets.


![](https://cdn-images-1.medium.com/max/1600/1*ReJHU_uDd_URCrWnfUbLkw.png)


Explosive growth — All the named GAN variants cumulatively since 2014.
Credit: [Bruno Gavranović](https://github.com/bgavran)

So, here’s the current and frequently updated list, from what started as
a fun activity compiling all named GANs in this format: **Name** and
**Source Paper** linked to [Arxiv](https://arxiv.org). Last updated on Feb 23, 2018.


------------------------------------------------------------------------



    
- 3D-ED-GAN — [Shape Inpainting using 3D Generative Adversarial Network and Recurrent Convolutional Networks](https://arxiv.org/abs/1711.06375)
    
- 3D-GAN — [Learning a Probabilistic Latent Space of Object Shapes via 3D Generative-Adversarial Modeling](https://arxiv.org/abs/1610.07584)([github](https://github.com/zck119/3dgan-release))

- 3D-IWGAN — [Improved Adversarial Systems for 3D Object Generation and
    Reconstruction](https://arxiv.org/abs/1707.09557)([github](https://github.com/EdwardSmith1884/3D-IWGAN))
- 3D-RecGAN — [3D Object Reconstruction from a Single Depth View with Adversarial
    Learning](https://arxiv.org/abs/1708.07969)([github](https://github.com/Yang7879/3D-RecGAN))
- ABC-GAN — [ABC-GAN: Adaptive Blur and Control for improved training stability of Generative Adversarial Networks](https://drive.google.com/file/d/0B3wEP_lEl0laVTdGcHE2VnRiMlE/view)([github](https://github.com/IgorSusmelj/ABC-GAN))
- ABC-GAN — [GANs for LIFE: Generative Adversarial Networks for
    Likelihood Free
    Inference](https://arxiv.org/abs/1711.11139)
- AC-GAN — [Conditional Image Synthesis With Auxiliary Classifier
    GANs](https://arxiv.org/abs/1610.09585)
- acGAN — [Face Aging With Conditional Generative Adversarial
    Networks](https://arxiv.org/abs/1702.01983)
- ACGAN — [Coverless Information Hiding Based on Generative
    adversarial
    networks](https://arxiv.org/abs/1712.06951)
- ACtuAL — [ACtuAL: Actor-Critic Under Adversarial
    Learning](https://arxiv.org/abs/1711.04755)
- AdaGAN — [AdaGAN: Boosting Generative
    Models](https://arxiv.org/abs/1701.02386v1)
-   AdvGAN — [Generating adversarial examples with adversarial
    networks](https://arxiv.org/abs/1801.02610)
-  AE-GAN — [AE-GAN: adversarial eliminating with
    GAN](https://arxiv.org/abs/1707.05474)
-  AEGAN — [Learning Inverse Mapping by Autoencoder based Generative
    Adversarial Nets](https://arxiv.org/abs/1703.10094)
-  AF-DCGAN — [AF-DCGAN: Amplitude Feature Deep Convolutional GAN for
    Fingerprint Construction in Indoor Localization
    System](https://arxiv.org/abs/1804.05347)
-  AffGAN — [Amortised MAP Inference for Image
    Super-resolution](https://arxiv.org/abs/1610.04490)
- AL-CGAN — [Learning to Generate Images of Outdoor Scenes from
    Attributes and Semantic
    Layouts](https://arxiv.org/abs/1612.00215)
- ALI — [Adversarially Learned
    Inference](https://arxiv.org/abs/1606.00704)
([github](https://github.com/IshmaelBelghazi/ALI)
    )
- AlignGAN — [AlignGAN: Learning to Align Cross-Domain Images with
    Conditional Generative Adversarial
    Networks](https://arxiv.org/abs/1707.01400)
- AM-GAN — [Activation Maximization Generative Adversarial
    Nets](https://arxiv.org/abs/1703.02000)
- AnoGAN — [Unsupervised Anomaly Detection with Generative Adversarial
    Networks to Guide Marker
    Discovery](https://arxiv.org/abs/1703.05921v1)
- APE-GAN — [APE-GAN: Adversarial Perturbation Elimination with
    GAN](https://arxiv.org/abs/1707.05474)
- ARAE — [Adversarially Regularized Autoencoders for Generating
    Discrete
    Structures](https://arxiv.org/abs/1706.04223)
([github](https://github.com/jakezhaojb/ARAE)
    )
- ARDA — [Adversarial Representation Learning for Domain
    Adaptation](https://arxiv.org/abs/1707.01217)
- ARIGAN — [ARIGAN: Synthetic Arabidopsis Plants using Generative
    Adversarial
    Network](https://arxiv.org/abs/1709.00938)
- ArtGAN — [ArtGAN: Artwork Synthesis with Conditional Categorial
    GANs](https://arxiv.org/abs/1702.03410)
- ATA-GAN — [Attention-Aware Generative Adversarial Networks
    (ATA-GANs)](https://arxiv.org/abs/1802.09070)
- Attention-GAN — [Attention-GAN for Object Transfiguration in Wild
    Images](https://arxiv.org/abs/1803.06798)
- AttGAN — [Arbitrary Facial Attribute Editing: Only Change What You
    Want](https://arxiv.org/abs/1711.10678)
- AttnGAN — [AttnGAN: Fine-Grained Text to Image Generation with
    Attentional Generative Adversarial
    Networks](https://arxiv.org/abs/1711.10485)
- B-DCGAN — [B-DCGAN:Evaluation of Binarized DCGAN for
    FPGA](https://arxiv.org/abs/1803.10930)
- b-GAN — [Generative Adversarial Nets from a Density Ratio Estimation
    Perspective](https://arxiv.org/abs/1610.02920)
- BAGAN — [BAGAN: Data Augmentation with Balancing
    GAN](https://arxiv.org/abs/1803.09655)
- Bayesian GAN — [Deep and Hierarchical Implicit
    Models](https://arxiv.org/abs/1702.08896)
- Bayesian GAN — [Bayesian
    GAN](https://arxiv.org/abs/1705.09558)
([github](https://github.com/andrewgordonwilson/bayesgan/)
    )
- BCGAN — [Bayesian Conditional Generative Adverserial
    Networks](https://arxiv.org/abs/1706.05477)
- BCGAN — [Bidirectional Conditional Generative Adversarial
    networks](https://arxiv.org/abs/1711.07461)
- BEGAN — [BEGAN: Boundary Equilibrium Generative Adversarial
    Networks](https://arxiv.org/abs/1703.10717)
- BGAN — [Binary Generative Adversarial Networks for Image
    Retrieval](https://arxiv.org/abs/1708.04150)
([github](https://github.com/htconquer/BGAN)
    )
- BicycleGAN — [Toward Multimodal Image-to-Image
    Translation](https://arxiv.org/abs/1711.11586)
([github](https://github.com/junyanz/BicycleGAN)
    )
- BiGAN — [Adversarial Feature
    Learning](https://arxiv.org/abs/1605.09782v7)
- BranchGAN — [Branched Generative Adversarial Networks for
    Multi-Scale Image Manifold
    Learning](https://arxiv.org/abs/1803.08467)
-  BS-GAN — [Boundary-Seeking Generative Adversarial
    Networks](https://arxiv.org/abs/1702.08431v1)
- C-GAN — [Face Aging with Contextual Generative Adversarial
    Nets](https://arxiv.org/abs/1802.00237)
- C-RNN-GAN — [C-RNN-GAN: Continuous recurrent neural networks with
    adversarial
    training](https://arxiv.org/abs/1611.09904)
([github](https://github.com/olofmogren/c-rnn-gan/)
    )
- CA-GAN — [Composition-aided Sketch-realistic Portrait
    Generation](https://arxiv.org/abs/1712.00899)
    
<li name="8ff1" id="8ff1" class="graf graf--li graf-after--li">CA-GAN — <a href="https://arxiv.org/abs/1712.00899" data-href="https://arxiv.org/abs/1712.00899" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Composition-aided Sketch-realistic Portrait Generation</a></li>
<li name="8ff1" id="8ff1" class="graf graf--li graf-after--li">CaloGAN — <a href="https://arxiv.org/abs/1705.02355" data-href="https://arxiv.org/abs/1705.02355" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">CaloGAN: Simulating 3D High Energy Particle Showers in Multi-Layer Electromagnetic Calorimeters with Generative Adversarial Networks</a> (<a href="https://github.com/hep-lbdl/CaloGAN" data-href="https://github.com/hep-lbdl/CaloGAN" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">github</a>)</li><li name="65ad" id="65ad" class="graf graf--li graf-after--li">CAN — <a href="https://arxiv.org/abs/1706.07068" data-href="https://arxiv.org/abs/1706.07068" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">CAN: Creative Adversarial Networks, Generating Art by Learning About Styles and Deviating from Style Norms</a></li><li name="187b" id="187b" class="graf graf--li graf-after--li">CapsuleGAN — <a href="http://arxiv.org/abs/1802.06167" data-href="http://arxiv.org/abs/1802.06167" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">CapsuleGAN: Generative Adversarial Capsule Network</a></li><li name="deff" id="deff" class="graf graf--li graf-after--li">CatGAN — <a href="https://arxiv.org/abs/1511.06390v2" data-href="https://arxiv.org/abs/1511.06390v2" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Unsupervised and Semi-supervised Learning with Categorical Generative Adversarial Networks</a></li><li name="9e9d" id="9e9d" class="graf graf--li graf-after--li">CatGAN — <a href="https://arxiv.org/abs/1711.08904" data-href="https://arxiv.org/abs/1711.08904" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">CatGAN: Coupled Adversarial Transfer for Domain Generation</a></li><li name="1cbe" id="1cbe" class="graf graf--li graf-after--li">CausalGAN — <a href="https://arxiv.org/abs/1709.02023" data-href="https://arxiv.org/abs/1709.02023" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">CausalGAN: Learning Causal Implicit Generative Models with Adversarial Training</a></li><li name="7642" id="7642" class="graf graf--li graf-after--li">CC-GAN — <a href="https://arxiv.org/abs/1611.06430" data-href="https://arxiv.org/abs/1611.06430" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Semi-Supervised Learning with Context-Conditional Generative Adversarial Networks</a> (<a href="https://github.com/edenton/cc-gan" data-href="https://github.com/edenton/cc-gan" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">github</a>)</li><li name="8a43" id="8a43" class="graf graf--li graf-after--li">CDcGAN — <a href="https://arxiv.org/abs/1708.09105" data-href="https://arxiv.org/abs/1708.09105" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Simultaneously Color-Depth Super-Resolution with Conditional Generative Adversarial Network</a></li><li name="d4b9" id="d4b9" class="graf graf--li graf-after--li">CFG-GAN — <a href="https://arxiv.org/abs/1801.06309" data-href="https://arxiv.org/abs/1801.06309" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Composite Functional Gradient Learning of Generative Adversarial Models</a></li><li name="f283" id="f283" class="graf graf--li graf-after--li">CGAN — <a href="https://arxiv.org/abs/1411.1784" data-href="https://arxiv.org/abs/1411.1784" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Conditional Generative Adversarial Nets</a></li><li name="cf37" id="cf37" class="graf graf--li graf-after--li">CGAN — <a href="https://arxiv.org/abs/1708.00598" data-href="https://arxiv.org/abs/1708.00598" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Controllable Generative Adversarial Network</a></li><li name="d980" id="d980" class="graf graf--li graf-after--li">Chekhov GAN — <a href="https://arxiv.org/abs/1706.03269" data-href="https://arxiv.org/abs/1706.03269" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">An Online Learning Approach to Generative Adversarial Networks</a></li><li name="34b4" id="34b4" class="graf graf--li graf-after--li">CipherGAN — <a href="https://arxiv.org/abs/1801.04883" data-href="https://arxiv.org/abs/1801.04883" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Unsupervised Cipher Cracking Using Discrete GANs</a></li><li name="ba60" id="ba60" class="graf graf--li graf-after--li">CM-GAN — <a href="https://arxiv.org/abs/1710.05106" data-href="https://arxiv.org/abs/1710.05106" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">CM-GANs: Cross-modal Generative Adversarial Networks for Common Representation Learning</a></li><li name="c0cd" id="c0cd" class="graf graf--li graf-after--li">CoAtt-GAN — <a href="https://arxiv.org/abs/1711.07613" data-href="https://arxiv.org/abs/1711.07613" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Are You Talking to Me? Reasoned Visual Dialog Generation through Adversarial Learning</a></li><li name="1cdf" id="1cdf" class="graf graf--li graf-after--li">CoGAN — <a href="https://arxiv.org/abs/1606.07536v2" data-href="https://arxiv.org/abs/1606.07536v2" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Coupled Generative Adversarial Networks</a></li><li name="eb41" id="eb41" class="graf graf--li graf-after--li">ComboGAN — <a href="https://arxiv.org/abs/1712.06909" data-href="https://arxiv.org/abs/1712.06909" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">ComboGAN: Unrestrained Scalability for Image Domain Translation</a> (<a href="https://github.com/AAnoosheh/ComboGAN" data-href="https://github.com/AAnoosheh/ComboGAN" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">github</a>)</li><li name="0ff7" id="0ff7" class="graf graf--li graf-after--li">ConceptGAN — <a href="https://arxiv.org/abs/1711.06148" data-href="https://arxiv.org/abs/1711.06148" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Learning Compositional Visual Concepts with Mutual Consistency</a></li><li name="44fb" id="44fb" class="graf graf--li graf-after--li">Conditional cycleGAN — <a href="https://arxiv.org/abs/1705.09966" data-href="https://arxiv.org/abs/1705.09966" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Conditional CycleGAN for Attribute Guided Face Image Generation</a></li><li name="b2e3" id="b2e3" class="graf graf--li graf-after--li">constrast-GAN — <a href="https://arxiv.org/abs/1708.00315" data-href="https://arxiv.org/abs/1708.00315" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Generative Semantic Manipulation with Contrasting GAN</a></li><li name="0779" id="0779" class="graf graf--li graf-after--li">Context-RNN-GAN — <a href="https://arxiv.org/abs/1609.09444" data-href="https://arxiv.org/abs/1609.09444" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Contextual RNN-GANs for Abstract Reasoning Diagram Generation</a></li><li name="253d" id="253d" class="graf graf--li graf-after--li">CorrGAN — <a href="https://arxiv.org/abs/1804.00925" data-href="https://arxiv.org/abs/1804.00925" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Correlated discrete data generation using adversarial training</a></li><li name="9e09" id="9e09" class="graf graf--li graf-after--li">Coulomb GAN — <a href="https://arxiv.org/abs/1708.08819" data-href="https://arxiv.org/abs/1708.08819" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Coulomb GANs: Provably Optimal Nash Equilibria via Potential Fields</a></li><li name="9a5e" id="9a5e" class="graf graf--li graf-after--li">Cover-GAN — <a href="https://arxiv.org/abs/1711.04916" data-href="https://arxiv.org/abs/1711.04916" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Generative Steganography with Kerckhoffs’ Principle based on Generative Adversarial Networks</a></li><li name="4646" id="4646" class="graf graf--li graf-after--li">Cramèr GAN — <a href="https://arxiv.org/abs/1705.10743" data-href="https://arxiv.org/abs/1705.10743" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">The Cramer Distance as a Solution to Biased Wasserstein Gradients</a></li><li name="7366" id="7366" class="graf graf--li graf-after--li">Cross-GAN — <a href="https://arxiv.org/abs/1801.01760" data-href="https://arxiv.org/abs/1801.01760" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Crossing Generative Adversarial Networks for Cross-View Person Re-identification</a></li><li name="0ddc" id="0ddc" class="graf graf--li graf-after--li">crVAE-GAN — <a href="https://arxiv.org/abs/1706.03729" data-href="https://arxiv.org/abs/1706.03729" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Channel-Recurrent Variational Autoencoders</a></li><li name="bc6c" id="bc6c" class="graf graf--li graf-after--li">CS-GAN — <a href="https://arxiv.org/abs/1703.04887" data-href="https://arxiv.org/abs/1703.04887" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Improving Neural Machine Translation with Conditional Sequence Generative Adversarial Nets</a></li><li name="2964" id="2964" class="graf graf--li graf-after--li">CVAE-GAN — <a href="https://arxiv.org/abs/1703.10155" data-href="https://arxiv.org/abs/1703.10155" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">CVAE-GAN: Fine-Grained Image Generation through Asymmetric Training</a></li><li name="59b0" id="59b0" class="graf graf--li graf-after--li">CycleGAN — <a href="https://arxiv.org/abs/1703.10593" data-href="https://arxiv.org/abs/1703.10593" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks</a> (<a href="https://github.com/junyanz/CycleGAN" data-href="https://github.com/junyanz/CycleGAN" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">github</a>)</li><li name="287f" id="287f" class="graf graf--li graf-after--li">D-GAN — <a href="https://arxiv.org/abs/1711.10267" data-href="https://arxiv.org/abs/1711.10267" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Differential Generative Adversarial Networks: Synthesizing Non-linear Facial Variations with Limited Number of Training Data</a></li><li name="d2a1" id="d2a1" class="graf graf--li graf-after--li">D-WCGAN — <a href="https://arxiv.org/abs/1804.00290" data-href="https://arxiv.org/abs/1804.00290" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">I-vector Transformation Using Conditional Generative Adversarial Networks for Short Utterance Speaker Verification</a></li><li name="bcbb" id="bcbb" class="graf graf--li graf-after--li">D2GAN — <a href="http://arxiv.org/abs/1709.03831" data-href="http://arxiv.org/abs/1709.03831" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Dual Discriminator Generative Adversarial Nets</a></li><li name="2586" id="2586" class="graf graf--li graf-after--li">D2IA-GAN — <a href="https://arxiv.org/abs/1804.00113" data-href="https://arxiv.org/abs/1804.00113" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Tagging like Humans: Diverse and Distinct Image Annotation</a></li><li name="588f" id="588f" class="graf graf--li graf-after--li">DA-GAN — <a href="http://arxiv.org/abs/1802.06454" data-href="http://arxiv.org/abs/1802.06454" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">DA-GAN: Instance-level Image Translation by Deep Attention Generative Adversarial Networks (with Supplementary Materials)</a></li><li name="d7b6" id="d7b6" class="graf graf--li graf-after--li">DAGAN — <a href="https://arxiv.org/abs/1711.04340" data-href="https://arxiv.org/abs/1711.04340" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Data Augmentation Generative Adversarial Networks</a></li><li name="fe57" id="fe57" class="graf graf--li graf-after--li">DAN — <a href="https://arxiv.org/abs/1706.09549" data-href="https://arxiv.org/abs/1706.09549" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Distributional Adversarial Networks</a></li><li name="1c74" id="1c74" class="graf graf--li graf-after--li">DBLRGAN — <a href="https://arxiv.org/abs/1804.00533" data-href="https://arxiv.org/abs/1804.00533" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Adversarial Spatio-Temporal Learning for Video Deblurring</a></li><li name="f30e" id="f30e" class="graf graf--li graf-after--li">DCGAN — <a href="https://arxiv.org/abs/1511.06434" data-href="https://arxiv.org/abs/1511.06434" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks</a> (<a href="https://github.com/Newmu/dcgan_code" data-href="https://github.com/Newmu/dcgan_code" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">github</a>)</li><li name="d7df" id="d7df" class="graf graf--li graf-after--li">DeblurGAN — <a href="https://arxiv.org/abs/1711.07064" data-href="https://arxiv.org/abs/1711.07064" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">DeblurGAN: Blind Motion Deblurring Using Conditional Adversarial Networks</a> (<a href="https://github.com/KupynOrest/DeblurGAN" data-href="https://github.com/KupynOrest/DeblurGAN" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">github</a>)</li><li name="84a8" id="84a8" class="graf graf--li graf-after--li">Defense-GAN — <a href="https://openreview.net/forum?id=BkJ3ibb0-&amp;noteId=SJwPXJaHG" data-href="https://openreview.net/forum?id=BkJ3ibb0-&amp;noteId=SJwPXJaHG" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Defense-GAN: Protecting Classifiers Against Adversarial Attacks Using Generative Models</a></li><li name="4889" id="4889" class="graf graf--li graf-after--li">DeliGAN — <a href="https://arxiv.org/abs/1706.02071" data-href="https://arxiv.org/abs/1706.02071" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">DeLiGAN&nbsp;: Generative Adversarial Networks for Diverse and Limited Data</a> (<a href="https://github.com/val-iisc/deligan" data-href="https://github.com/val-iisc/deligan" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">github</a>)</li><li name="4ec8" id="4ec8" class="graf graf--li graf-after--li">DF-GAN — <a href="https://arxiv.org/abs/1712.04646" data-href="https://arxiv.org/abs/1712.04646" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Learning Disentangling and Fusing Networks for Face Completion Under Structured Occlusions</a></li><li name="5a8f" id="5a8f" class="graf graf--li graf-after--li">DiscoGAN — <a href="https://arxiv.org/abs/1703.05192v1" data-href="https://arxiv.org/abs/1703.05192v1" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Learning to Discover Cross-Domain Relations with Generative Adversarial Networks</a></li><li name="7bec" id="7bec" class="graf graf--li graf-after--li">DistanceGAN — <a href="https://arxiv.org/abs/1706.00826" data-href="https://arxiv.org/abs/1706.00826" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">One-Sided Unsupervised Domain Mapping</a></li><li name="65d1" id="65d1" class="graf graf--li graf-after--li">DM-GAN — <a href="https://arxiv.org/abs/1708.00284" data-href="https://arxiv.org/abs/1708.00284" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Dual Motion GAN for Future-Flow Embedded Video Prediction</a></li><li name="952e" id="952e" class="graf graf--li graf-after--li">DNA-GAN — <a href="https://arxiv.org/abs/1711.05415" data-href="https://arxiv.org/abs/1711.05415" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">DNA-GAN: Learning Disentangled Representations from Multi-Attribute Images</a></li><li name="426d" id="426d" class="graf graf--li graf-after--li">dp-GAN — <a href="https://arxiv.org/abs/1801.01594" data-href="https://arxiv.org/abs/1801.01594" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Differentially Private Releasing via Deep Generative Model</a></li><li name="7cec" id="7cec" class="graf graf--li graf-after--li">DP-GAN — <a href="https://arxiv.org/abs/1802.01345" data-href="https://arxiv.org/abs/1802.01345" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">DP-GAN: Diversity-Promoting Generative Adversarial Network for Generating Informative and Diversified Text</a></li><li name="70fc" id="70fc" class="graf graf--li graf-after--li">DPGAN — <a href="http://arxiv.org/abs/1802.06739" data-href="http://arxiv.org/abs/1802.06739" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Differentially Private Generative Adversarial Network</a></li><li name="0b4f" id="0b4f" class="graf graf--li graf-after--li">DR-GAN — <a href="https://arxiv.org/abs/1705.11136" data-href="https://arxiv.org/abs/1705.11136" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Representation Learning by Rotating Your Faces</a></li><li name="be57" id="be57" class="graf graf--li graf-after--li">DRAGAN — <a href="https://arxiv.org/abs/1705.07215" data-href="https://arxiv.org/abs/1705.07215" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">How to Train Your DRAGAN</a> (<a href="https://github.com/kodalinaveen3/DRAGAN" data-href="https://github.com/kodalinaveen3/DRAGAN" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">github</a>)</li><li name="ba19" id="ba19" class="graf graf--li graf-after--li">DRPAN — <a href="https://arxiv.org/abs/1711.09554" data-href="https://arxiv.org/abs/1711.09554" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Discriminative Region Proposal Adversarial Networks for High-Quality Image-to-Image Translation</a></li><li name="da99" id="da99" class="graf graf--li graf-after--li">DSP-GAN — <a href="https://arxiv.org/abs/1706.00212" data-href="https://arxiv.org/abs/1706.00212" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Depth Structure Preserving Scene Image Generation</a></li><li name="894d" id="894d" class="graf graf--li graf-after--li">DTN — <a href="https://arxiv.org/abs/1611.02200" data-href="https://arxiv.org/abs/1611.02200" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Unsupervised Cross-Domain Image Generation</a></li><li name="f079" id="f079" class="graf graf--li graf-after--li">DualGAN — <a href="https://arxiv.org/abs/1704.02510v1" data-href="https://arxiv.org/abs/1704.02510v1" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">DualGAN: Unsupervised Dual Learning for Image-to-Image Translation</a></li><li name="50e7" id="50e7" class="graf graf--li graf-after--li">Dualing GAN — <a href="https://arxiv.org/abs/1706.06216" data-href="https://arxiv.org/abs/1706.06216" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Dualing GANs</a></li><li name="7457" id="7457" class="graf graf--li graf-after--li">Dynamics Transfer GAN — <a href="https://arxiv.org/abs/1712.03534" data-href="https://arxiv.org/abs/1712.03534" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Dynamics Transfer GAN: Generating Video by Transferring Arbitrary Temporal Dynamics from a Source Video to a Single Target Image</a></li><li name="eb2c" id="eb2c" class="graf graf--li graf-after--li">E-GAN — <a href="https://arxiv.org/abs/1803.00657" data-href="https://arxiv.org/abs/1803.00657" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Evolutionary Generative Adversarial Networks</a></li><li name="6bf2" id="6bf2" class="graf graf--li graf-after--li">EBGAN — <a href="https://arxiv.org/abs/1609.03126v4" data-href="https://arxiv.org/abs/1609.03126v4" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Energy-based Generative Adversarial Network</a></li><li name="663d" id="663d" class="graf graf--li graf-after--li">ecGAN — <a href="https://arxiv.org/abs/1801.03244" data-href="https://arxiv.org/abs/1801.03244" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">eCommerceGAN&nbsp;: A Generative Adversarial Network for E-commerce</a></li><li name="99cc" id="99cc" class="graf graf--li graf-after--li">ED//GAN — <a href="https://arxiv.org/abs/1705.09367" data-href="https://arxiv.org/abs/1705.09367" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Stabilizing Training of Generative Adversarial Networks through Regularization</a></li><li name="4451" id="4451" class="graf graf--li graf-after--li">EGAN — <a href="https://arxiv.org/abs/1705.08245" data-href="https://arxiv.org/abs/1705.08245" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Enhanced Experience Replay Generation for Efficient Reinforcement Learning</a></li><li name="677a" id="677a" class="graf graf--li graf-after--li">ELEGANT — <a href="https://arxiv.org/abs/1803.10562" data-href="https://arxiv.org/abs/1803.10562" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">ELEGANT: Exchanging Latent Encodings with GAN for Transferring Multiple Face Attributes</a></li><li name="e58e" id="e58e" class="graf graf--li graf-after--li">EnergyWGAN — <a href="https://arxiv.org/abs/1712.01026" data-href="https://arxiv.org/abs/1712.01026" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Energy-relaxed Wassertein GANs (EnergyWGAN): Towards More Stable and High Resolution Image Generation</a></li><li name="23f0" id="23f0" class="graf graf--li graf-after--li">ExGAN — <a href="https://arxiv.org/abs/1712.03999" data-href="https://arxiv.org/abs/1712.03999" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Eye In-Painting with Exemplar Generative Adversarial Networks</a></li><li name="a269" id="a269" class="graf graf--li graf-after--li">ExposureGAN — <a href="https://arxiv.org/abs/1709.09602" data-href="https://arxiv.org/abs/1709.09602" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Exposure: A White-Box Photo Post-Processing Framework</a> (<a href="https://github.com/yuanming-hu/exposure" data-href="https://github.com/yuanming-hu/exposure" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">github</a>)</li><li name="cfe9" id="cfe9" class="graf graf--li graf-after--li">ExprGAN — <a href="https://arxiv.org/abs/1709.03842" data-href="https://arxiv.org/abs/1709.03842" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">ExprGAN: Facial Expression Editing with Controllable Expression Intensity</a></li><li name="89b0" id="89b0" class="graf graf--li graf-after--li">f-CLSWGAN — <a href="https://arxiv.org/abs/1712.00981" data-href="https://arxiv.org/abs/1712.00981" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Feature Generating Networks for Zero-Shot Learning</a></li><li name="b060" id="b060" class="graf graf--li graf-after--li">f-GAN — <a href="https://arxiv.org/abs/1606.00709" data-href="https://arxiv.org/abs/1606.00709" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">f-GAN: Training Generative Neural Samplers using Variational Divergence Minimization</a></li><li name="cf32" id="cf32" class="graf graf--li graf-after--li">FBGAN — <a href="https://arxiv.org/abs/1804.01694" data-href="https://arxiv.org/abs/1804.01694" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Feedback GAN (FBGAN) for DNA: a Novel Feedback-Loop Architecture for Optimizing Protein Functions</a></li><li name="5341" id="5341" class="graf graf--li graf-after--li">FF-GAN — <a href="https://arxiv.org/abs/1704.06244" data-href="https://arxiv.org/abs/1704.06244" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Towards Large-Pose Face Frontalization in the Wild</a></li><li name="b601" id="b601" class="graf graf--li graf-after--li">Fictitious GAN — <a href="https://arxiv.org/abs/1803.08647" data-href="https://arxiv.org/abs/1803.08647" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Fictitious GAN: Training GANs with Historical Models</a></li><li name="ea4b" id="ea4b" class="graf graf--li graf-after--li">FIGAN — <a href="https://arxiv.org/abs/1711.06045" data-href="https://arxiv.org/abs/1711.06045" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Frame Interpolation with Multi-Scale Deep Loss Functions and Generative Adversarial Networks</a></li><li name="221f" id="221f" class="graf graf--li graf-after--li">Fila-GAN — <a href="https://arxiv.org/abs/1706.02185" data-href="https://arxiv.org/abs/1706.02185" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Synthesizing Filamentary Structured Images with GANs</a></li><li name="9665" id="9665" class="graf graf--li graf-after--li">First Order GAN — <a href="https://arxiv.org/abs/1802.04591" data-href="https://arxiv.org/abs/1802.04591" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">First Order Generative Adversarial Networks </a>(<a href="https://github.com/zalandoresearch/first_order_gan" data-href="https://github.com/zalandoresearch/first_order_gan" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">github</a>)</li><li name="0989" id="0989" class="graf graf--li graf-after--li">Fisher GAN — <a href="https://arxiv.org/abs/1705.09675" data-href="https://arxiv.org/abs/1705.09675" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Fisher GAN</a></li><li name="85a9" id="85a9" class="graf graf--li graf-after--li">Flow-GAN — <a href="https://arxiv.org/abs/1705.08868" data-href="https://arxiv.org/abs/1705.08868" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Flow-GAN: Bridging implicit and prescribed learning in generative models</a></li><li name="c411" id="c411" class="graf graf--li graf-after--li">FSEGAN — <a href="https://arxiv.org/abs/1711.05747" data-href="https://arxiv.org/abs/1711.05747" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Exploring Speech Enhancement with Generative Adversarial Networks for Robust Speech Recognition</a></li><li name="c1d7" id="c1d7" class="graf graf--li graf-after--li">FTGAN — <a href="https://arxiv.org/abs/1711.09618" data-href="https://arxiv.org/abs/1711.09618" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Hierarchical Video Generation from Orthogonal Information: Optical Flow and Texture</a></li><li name="6ed6" id="6ed6" class="graf graf--li graf-after--li">FusedGAN — <a href="https://arxiv.org/abs/1801.05551" data-href="https://arxiv.org/abs/1801.05551" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Semi-supervised FusedGAN for Conditional Image Generation</a></li><li name="f448" id="f448" class="graf graf--li graf-after--li">FusionGAN — <a href="https://arxiv.org/abs/1712.01456" data-href="https://arxiv.org/abs/1712.01456" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Learning to Fuse Music Genres with Generative Adversarial Dual Learning</a></li><li name="972b" id="972b" class="graf graf--li graf-after--li">G2-GAN — <a href="https://arxiv.org/abs/1712.03474" data-href="https://arxiv.org/abs/1712.03474" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Geometry Guided Adversarial Facial Expression Synthesis</a></li><li name="6775" id="6775" class="graf graf--li graf-after--li">GAAN — <a href="https://arxiv.org/abs/1803.08887" data-href="https://arxiv.org/abs/1803.08887" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Generative Adversarial Autoencoder Networks</a></li><li name="75f2" id="75f2" class="graf graf--li graf-after--li">GAGAN — <a href="https://arxiv.org/abs/1712.00684" data-href="https://arxiv.org/abs/1712.00684" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">GAGAN: Geometry-Aware Generative Adverserial Networks</a></li><li name="8734" id="8734" class="graf graf--li graf-after--li">GAMN — <a href="https://arxiv.org/abs/1709.09820" data-href="https://arxiv.org/abs/1709.09820" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Generative Adversarial Mapping Networks</a></li><li name="86b9" id="86b9" class="graf graf--li graf-after--li">GAN — <a href="https://arxiv.org/abs/1406.2661" data-href="https://arxiv.org/abs/1406.2661" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Generative Adversarial Networks</a> (<a href="https://github.com/goodfeli/adversarial" data-href="https://github.com/goodfeli/adversarial" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">github</a>)</li><li name="088f" id="088f" class="graf graf--li graf-after--li">GAN-ATV — <a href="https://arxiv.org/abs/1710.10553" data-href="https://arxiv.org/abs/1710.10553" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">A Novel Approach to Artistic Textual Visualization via GAN</a></li><li name="d8ab" id="d8ab" class="graf graf--li graf-after--li">GAN-CLS — <a href="https://arxiv.org/abs/1605.05396" data-href="https://arxiv.org/abs/1605.05396" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Generative Adversarial Text to Image Synthesis</a> (<a href="https://github.com/reedscot/icml2016" data-href="https://github.com/reedscot/icml2016" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">github</a>)</li><li name="2739" id="2739" class="graf graf--li graf-after--li">GAN-RS — <a href="https://arxiv.org/abs/1712.00736" data-href="https://arxiv.org/abs/1712.00736" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Towards Qualitative Advancement of Underwater Machine Vision with Generative Adversarial Networks</a></li><li name="3152" id="3152" class="graf graf--li graf-after--li">GAN-sep — <a href="https://arxiv.org/abs/1708.04692" data-href="https://arxiv.org/abs/1708.04692" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">GANs for Biological Image Synthesis</a> (<a href="https://github.com/aosokin/biogans" data-href="https://github.com/aosokin/biogans" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">github</a>)</li><li name="40ea" id="40ea" class="graf graf--li graf-after--li">GAN-VFS — <a href="https://arxiv.org/abs/1708.02681" data-href="https://arxiv.org/abs/1708.02681" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Generative Adversarial Network-based Synthesis of Visible Faces from Polarimetric Thermal Faces</a></li><li name="abb9" id="abb9" class="graf graf--li graf-after--li">GANCS — <a href="https://arxiv.org/abs/1706.00051" data-href="https://arxiv.org/abs/1706.00051" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Deep Generative Adversarial Networks for Compressed Sensing Automates MRI</a></li><li name="79dc" id="79dc" class="graf graf--li graf-after--li">GANDI — <a href="https://arxiv.org/abs/1711.01391" data-href="https://arxiv.org/abs/1711.01391" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Guiding the search in continuous state-action spaces by learning an action sampling distribution from off-target samples</a></li><li name="e987" id="e987" class="graf graf--li graf-after--li">GANG — <a href="https://arxiv.org/abs/1712.00679" data-href="https://arxiv.org/abs/1712.00679" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">GANGs: Generative Adversarial Network Games</a></li><li name="d439" id="d439" class="graf graf--li graf-after--li">GANosaic — <a href="https://arxiv.org/abs/1712.00269" data-href="https://arxiv.org/abs/1712.00269" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">GANosaic: Mosaic Creation with Generative Texture Manifolds</a></li><li name="3515" id="3515" class="graf graf--li graf-after--li">GAP — <a href="https://arxiv.org/abs/1710.09549" data-href="https://arxiv.org/abs/1710.09549" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Context-Aware Generative Adversarial Privacy</a></li><li name="60b9" id="60b9" class="graf graf--li graf-after--li">GAWWN — <a href="https://arxiv.org/abs/1610.02454" data-href="https://arxiv.org/abs/1610.02454" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Learning What and Where to Draw</a> (<a href="https://github.com/reedscot/nips2016" data-href="https://github.com/reedscot/nips2016" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">github</a>)</li><li name="bdc0" id="bdc0" class="graf graf--li graf-after--li">GC-GAN — <a href="https://arxiv.org/abs/1802.01822" data-href="https://arxiv.org/abs/1802.01822" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Geometry-Contrastive Generative Adversarial Network for Facial Expression Synthesis</a></li><li name="1753" id="1753" class="graf graf--li graf-after--li">GeneGAN — <a href="https://arxiv.org/abs/1705.04932" data-href="https://arxiv.org/abs/1705.04932" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">GeneGAN: Learning Object Transfiguration and Attribute Subspace from Unpaired Data</a> (<a href="https://github.com/Prinsphield/GeneGAN" data-href="https://github.com/Prinsphield/GeneGAN" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">github</a>)</li><li name="8e4c" id="8e4c" class="graf graf--li graf-after--li">GeoGAN — <a href="https://arxiv.org/abs/1801.08839" data-href="https://arxiv.org/abs/1801.08839" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Generating Instance Segmentation Annotation by Geometry-guided GAN</a></li><li name="62b6" id="62b6" class="graf graf--li graf-after--li">Geometric GAN — <a href="https://arxiv.org/abs/1705.02894" data-href="https://arxiv.org/abs/1705.02894" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Geometric GAN</a></li><li name="abdb" id="abdb" class="graf graf--li graf-after--li">GLCA-GAN — <a href="https://arxiv.org/abs/1801.08390" data-href="https://arxiv.org/abs/1801.08390" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Global and Local Consistent Age Generative Adversarial Networks</a></li><li name="fa1a" id="fa1a" class="graf graf--li graf-after--li">GMAN — <a href="http://arxiv.org/abs/1611.01673" data-href="http://arxiv.org/abs/1611.01673" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Generative Multi-Adversarial Networks</a></li><li name="5fcb" id="5fcb" class="graf graf--li graf-after--li">GMM-GAN — <a href="https://arxiv.org/abs/1706.09884" data-href="https://arxiv.org/abs/1706.09884" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Towards Understanding the Dynamics of Generative Adversarial Networks</a></li><li name="dc31" id="dc31" class="graf graf--li graf-after--li">GoGAN — <a href="https://arxiv.org/abs/1704.04865" data-href="https://arxiv.org/abs/1704.04865" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Gang of GANs: Generative Adversarial Networks with Maximum Margin Ranking</a></li><li name="a412" id="a412" class="graf graf--li graf-after--li">GONet — <a href="https://arxiv.org/abs/1803.03254" data-href="https://arxiv.org/abs/1803.03254" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">GONet: A Semi-Supervised Deep Learning Approach For Traversability Estimation</a></li><li name="db8f" id="db8f" class="graf graf--li graf-after--li">GP-GAN — <a href="https://arxiv.org/abs/1703.07195" data-href="https://arxiv.org/abs/1703.07195" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">GP-GAN: Towards Realistic High-Resolution Image Blending</a> (<a href="https://github.com/wuhuikai/GP-GAN" data-href="https://github.com/wuhuikai/GP-GAN" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">github</a>)</li><li name="74c2" id="74c2" class="graf graf--li graf-after--li">GP-GAN — <a href="https://arxiv.org/abs/1710.00962" data-href="https://arxiv.org/abs/1710.00962" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">GP-GAN: Gender Preserving GAN for Synthesizing Faces from Landmarks</a></li><li name="f7e6" id="f7e6" class="graf graf--li graf-after--li">GPU — <a href="https://arxiv.org/abs/1711.08054" data-href="https://arxiv.org/abs/1711.08054" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">A generative adversarial framework for positive-unlabeled classification</a></li><li name="f422" id="f422" class="graf graf--li graf-after--li">GRAN — <a href="https://arxiv.org/abs/1602.05110" data-href="https://arxiv.org/abs/1602.05110" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Generating images with recurrent adversarial networks</a> (<a href="https://github.com/jiwoongim/GRAN" data-href="https://github.com/jiwoongim/GRAN" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">github</a>)</li><li name="ffa9" id="ffa9" class="graf graf--li graf-after--li">Graphical-GAN — <a href="https://arxiv.org/abs/1804.03429" data-href="https://arxiv.org/abs/1804.03429" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Graphical Generative Adversarial Networks</a></li><li name="8009" id="8009" class="graf graf--li graf-after--li">GraspGAN — <a href="https://arxiv.org/abs/1709.07857" data-href="https://arxiv.org/abs/1709.07857" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Using Simulation and Domain Adaptation to Improve Efficiency of Deep Robotic Grasping</a></li><li name="322b" id="322b" class="graf graf--li graf-after--li">HAN — <a href="https://arxiv.org/abs/1711.06448" data-href="https://arxiv.org/abs/1711.06448" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Chinese Typeface Transformation with Hierarchical Adversarial Network</a></li><li name="f9fa" id="f9fa" class="graf graf--li graf-after--li">HP-GAN — <a href="https://arxiv.org/abs/1711.09561" data-href="https://arxiv.org/abs/1711.09561" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">HP-GAN: Probabilistic 3D human motion prediction via GAN</a></li><li name="4125" id="4125" class="graf graf--li graf-after--li">HR-DCGAN — <a href="https://arxiv.org/abs/1711.06491" data-href="https://arxiv.org/abs/1711.06491" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">High-Resolution Deep Convolutional Generative Adversarial Networks</a></li><li name="4bad" id="4bad" class="graf graf--li graf-after--li">IAN — <a href="https://arxiv.org/abs/1609.07093" data-href="https://arxiv.org/abs/1609.07093" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Neural Photo Editing with Introspective Adversarial Networks</a> (<a href="https://github.com/ajbrock/Neural-Photo-Editor" data-href="https://github.com/ajbrock/Neural-Photo-Editor" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">github</a>)</li><li name="097b" id="097b" class="graf graf--li graf-after--li">IcGAN — <a href="https://arxiv.org/abs/1611.06355" data-href="https://arxiv.org/abs/1611.06355" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Invertible Conditional GANs for image editing</a> (<a href="https://github.com/Guim3/IcGAN" data-href="https://github.com/Guim3/IcGAN" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">github</a>)</li><li name="1c4e" id="1c4e" class="graf graf--li graf-after--li">ID-CGAN — <a href="https://arxiv.org/abs/1701.05957v3" data-href="https://arxiv.org/abs/1701.05957v3" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Image De-raining Using a Conditional Generative Adversarial Network</a></li><li name="12d7" id="12d7" class="graf graf--li graf-after--li">IdCycleGAN — <a href="https://arxiv.org/abs/1712.00971" data-href="https://arxiv.org/abs/1712.00971" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Face Translation between Images and Videos using Identity-aware CycleGAN</a></li><li name="557c" id="557c" class="graf graf--li graf-after--li">IFcVAEGAN — <a href="https://arxiv.org/abs/1711.05175" data-href="https://arxiv.org/abs/1711.05175" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Conditional Autoencoders with Adversarial Information Factorization</a></li><li name="7c97" id="7c97" class="graf graf--li graf-after--li">iGAN — <a href="https://arxiv.org/abs/1609.03552v2" data-href="https://arxiv.org/abs/1609.03552v2" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Generative Visual Manipulation on the Natural Image Manifold</a> (<a href="https://github.com/junyanz/iGAN" data-href="https://github.com/junyanz/iGAN" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">github</a>)</li><li name="66b7" id="66b7" class="graf graf--li graf-after--li">Improved GAN — <a href="https://arxiv.org/abs/1606.03498" data-href="https://arxiv.org/abs/1606.03498" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Improved Techniques for Training GANs</a> (<a href="https://github.com/openai/improved-gan" data-href="https://github.com/openai/improved-gan" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">github</a>)</li><li name="f2de" id="f2de" class="graf graf--li graf-after--li">In2I — <a href="https://arxiv.org/abs/1711.09334" data-href="https://arxiv.org/abs/1711.09334" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">In2I&nbsp;: Unsupervised Multi-Image-to-Image Translation Using Generative Adversarial Networks</a></li><li name="383c" id="383c" class="graf graf--li graf-after--li">InfoGAN — <a href="https://arxiv.org/abs/1606.03657v1" data-href="https://arxiv.org/abs/1606.03657v1" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets</a>(<a href="https://github.com/openai/InfoGAN" data-href="https://github.com/openai/InfoGAN" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">github</a>)</li><li name="0fc6" id="0fc6" class="graf graf--li graf-after--li">IRGAN — <a href="https://arxiv.org/abs/1705.10513v1" data-href="https://arxiv.org/abs/1705.10513v1" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">IRGAN: A Minimax Game for Unifying Generative and Discriminative Information Retrieval models</a></li><li name="d9cb" id="d9cb" class="graf graf--li graf-after--li">Iterative-GAN — <a href="https://arxiv.org/abs/1711.06078" data-href="https://arxiv.org/abs/1711.06078" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Two Birds with One Stone: Iteratively Learn Facial Attributes with GANs</a> (<a href="https://github.com/punkcure/Iterative-GAN" data-href="https://github.com/punkcure/Iterative-GAN" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">github</a>)</li><li name="cbcb" id="cbcb" class="graf graf--li graf-after--li">IVE-GAN — <a href="https://arxiv.org/abs/1711.08646" data-href="https://arxiv.org/abs/1711.08646" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">IVE-GAN: Invariant Encoding Generative Adversarial Networks</a></li><li name="a7ee" id="a7ee" class="graf graf--li graf-after--li">iVGAN — <a href="https://arxiv.org/abs/1711.11453" data-href="https://arxiv.org/abs/1711.11453" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Towards an Understanding of Our World by GANing Videos in the Wild</a> (<a href="https://github.com/bernhard2202/improved-video-gan" data-href="https://github.com/bernhard2202/improved-video-gan" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">github</a>)</li><li name="5307" id="5307" class="graf graf--li graf-after--li">IWGAN — <a href="https://arxiv.org/abs/1706.00550" data-href="https://arxiv.org/abs/1706.00550" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">On Unifying Deep Generative Models</a></li><li name="c898" id="c898" class="graf graf--li graf-after--li">KBGAN — <a href="https://arxiv.org/abs/1711.04071" data-href="https://arxiv.org/abs/1711.04071" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">KBGAN: Adversarial Learning for Knowledge Graph Embeddings</a></li><li name="ad8b" id="ad8b" class="graf graf--li graf-after--li">KGAN — <a href="https://arxiv.org/abs/1711.01744" data-href="https://arxiv.org/abs/1711.01744" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">KGAN: How to Break The Minimax Game in GAN</a></li><li name="aae7" id="aae7" class="graf graf--li graf-after--li">l-GAN — <a href="https://arxiv.org/abs/1707.02392" data-href="https://arxiv.org/abs/1707.02392" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Representation Learning and Adversarial Generation of 3D Point Clouds</a></li><li name="6523" id="6523" class="graf graf--li graf-after--li">LAC-GAN — <a href="https://arxiv.org/abs/1801.05096" data-href="https://arxiv.org/abs/1801.05096" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Grounded Language Understanding for Manipulation Instructions Using GAN-Based Classification</a></li><li name="e8ea" id="e8ea" class="graf graf--li graf-after--li">LAGAN — <a href="https://arxiv.org/abs/1701.05927" data-href="https://arxiv.org/abs/1701.05927" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Learning Particle Physics by Example: Location-Aware Generative Adversarial Networks for Physics Synthesis</a></li><li name="679e" id="679e" class="graf graf--li graf-after--li">LAPGAN — <a href="https://arxiv.org/abs/1506.05751" data-href="https://arxiv.org/abs/1506.05751" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Deep Generative Image Models using a Laplacian Pyramid of Adversarial Networks</a> (<a href="https://github.com/facebook/eyescream" data-href="https://github.com/facebook/eyescream" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">github</a>)</li><li name="08f0" id="08f0" class="graf graf--li graf-after--li">LB-GAN — <a href="http://arxiv.org/abs/1802.07447" data-href="http://arxiv.org/abs/1802.07447" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Load Balanced GANs for Multi-view Face Image Synthesis</a></li><li name="a824" id="a824" class="graf graf--li graf-after--li">LD-GAN — <a href="https://arxiv.org/abs/1707.07831" data-href="https://arxiv.org/abs/1707.07831" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Linear Discriminant Generative Adversarial Networks</a></li><li name="f192" id="f192" class="graf graf--li graf-after--li">LDAN — <a href="https://arxiv.org/abs/1709.01993" data-href="https://arxiv.org/abs/1709.01993" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Label Denoising Adversarial Network (LDAN) for Inverse Lighting of Face Images</a></li><li name="06a5" id="06a5" class="graf graf--li graf-after--li">LeakGAN — <a href="https://arxiv.org/abs/1709.08624" data-href="https://arxiv.org/abs/1709.08624" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Long Text Generation via Adversarial Training with Leaked Information</a></li><li name="b50a" id="b50a" class="graf graf--li graf-after--li">LeGAN — <a href="https://arxiv.org/abs/1707.07530" data-href="https://arxiv.org/abs/1707.07530" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Likelihood Estimation for Generative Adversarial Networks</a></li><li name="88a4" id="88a4" class="graf graf--li graf-after--li">LGAN — <a href="https://arxiv.org/abs/1711.06020" data-href="https://arxiv.org/abs/1711.06020" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Global versus Localized Generative Adversarial Nets</a></li><li name="0ee1" id="0ee1" class="graf graf--li graf-after--li">LR-GAN — <a href="https://arxiv.org/abs/1703.01560v1" data-href="https://arxiv.org/abs/1703.01560v1" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">LR-GAN: Layered Recursive Generative Adversarial Networks for Image Generation</a></li><li name="a2f8" id="a2f8" class="graf graf--li graf-after--li">LS-GAN — <a href="https://arxiv.org/abs/1701.06264" data-href="https://arxiv.org/abs/1701.06264" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Loss-Sensitive Generative Adversarial Networks on Lipschitz Densities</a></li><li name="4e07" id="4e07" class="graf graf--li graf-after--li">LSGAN — <a href="https://arxiv.org/abs/1611.04076v3" data-href="https://arxiv.org/abs/1611.04076v3" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Least Squares Generative Adversarial Networks</a></li><li name="3741" id="3741" class="graf graf--li graf-after--li">MAD-GAN — <a href="https://arxiv.org/abs/1704.02906" data-href="https://arxiv.org/abs/1704.02906" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Multi-Agent Diverse Generative Adversarial Networks</a></li><li name="f029" id="f029" class="graf graf--li graf-after--li">MAGAN — <a href="https://arxiv.org/abs/1704.03817v1" data-href="https://arxiv.org/abs/1704.03817v1" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">MAGAN: Margin Adaptation for Generative Adversarial Networks</a></li><li name="867d" id="867d" class="graf graf--li graf-after--li">MAGAN — <a href="https://arxiv.org/abs/1803.00385" data-href="https://arxiv.org/abs/1803.00385" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">MAGAN: Aligning Biological Manifolds</a></li><li name="1c97" id="1c97" class="graf graf--li graf-after--li">MalGAN — <a href="https://arxiv.org/abs/1702.05983v1" data-href="https://arxiv.org/abs/1702.05983v1" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Generating Adversarial Malware Examples for Black-Box Attacks Based on GAN</a></li><li name="9981" id="9981" class="graf graf--li graf-after--li">MaliGAN — <a href="https://arxiv.org/abs/1702.07983" data-href="https://arxiv.org/abs/1702.07983" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Maximum-Likelihood Augmented Discrete Generative Adversarial Networks</a></li><li name="82e2" id="82e2" class="graf graf--li graf-after--li">manifold-WGAN — <a href="https://arxiv.org/abs/1712.01551" data-href="https://arxiv.org/abs/1712.01551" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Manifold-valued Image Generation with Wasserstein Adversarial Networks</a></li><li name="5b83" id="5b83" class="graf graf--li graf-after--li">MARTA-GAN — <a href="https://arxiv.org/abs/1612.08879" data-href="https://arxiv.org/abs/1612.08879" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Deep Unsupervised Representation Learning for Remote Sensing Images</a></li><li name="3e2a" id="3e2a" class="graf graf--li graf-after--li">MaskGAN — <a href="https://arxiv.org/abs/1801.07736" data-href="https://arxiv.org/abs/1801.07736" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">MaskGAN: Better Text Generation via Filling in the ______</a></li><li name="6633" id="6633" class="graf graf--li graf-after--li">MC-GAN — <a href="https://arxiv.org/abs/1712.00516" data-href="https://arxiv.org/abs/1712.00516" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Multi-Content GAN for Few-Shot Font Style Transfer</a> (<a href="https://github.com/azadis/MC-GAN" data-href="https://github.com/azadis/MC-GAN" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">github</a>)</li><li name="34f8" id="34f8" class="graf graf--li graf-after--li">McGAN — <a href="https://arxiv.org/abs/1702.08398v1" data-href="https://arxiv.org/abs/1702.08398v1" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">McGan: Mean and Covariance Feature Matching GAN</a></li><li name="2dc4" id="2dc4" class="graf graf--li graf-after--li">MD-GAN — <a href="https://arxiv.org/abs/1709.07592" data-href="https://arxiv.org/abs/1709.07592" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Learning to Generate Time-Lapse Videos Using Multi-Stage Dynamic Generative Adversarial Networks</a></li><li name="79ba" id="79ba" class="graf graf--li graf-after--li">MDGAN — <a href="https://arxiv.org/abs/1612.02136" data-href="https://arxiv.org/abs/1612.02136" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Mode Regularized Generative Adversarial Networks</a></li><li name="07f7" id="07f7" class="graf graf--li graf-after--li">MedGAN — <a href="https://arxiv.org/abs/1703.06490v1" data-href="https://arxiv.org/abs/1703.06490v1" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Generating Multi-label Discrete Electronic Health Records using Generative Adversarial Networks</a></li><li name="e1be" id="e1be" class="graf graf--li graf-after--li">MelanoGAN — <a href="https://arxiv.org/abs/1804.04338" data-href="https://arxiv.org/abs/1804.04338" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">MelanoGANs: High Resolution Skin Lesion Synthesis with GANs</a></li><li name="7145" id="7145" class="graf graf--li graf-after--li">memoryGAN — <a href="https://arxiv.org/abs/1803.01500" data-href="https://arxiv.org/abs/1803.01500" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Memorization Precedes Generation: Learning Unsupervised GANs with Memory Networks</a></li><li name="d9de" id="d9de" class="graf graf--li graf-after--li">MGAN — <a href="https://arxiv.org/abs/1604.04382" data-href="https://arxiv.org/abs/1604.04382" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Precomputed Real-Time Texture Synthesis with Markovian Generative Adversarial Networks</a> (<a href="https://github.com/chuanli11/MGANs" data-href="https://github.com/chuanli11/MGANs" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">github</a>)</li><li name="50c2" id="50c2" class="graf graf--li graf-after--li">MGGAN — <a href="https://arxiv.org/abs/1708.02556" data-href="https://arxiv.org/abs/1708.02556" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Multi-Generator Generative Adversarial Nets</a></li><li name="ce1b" id="ce1b" class="graf graf--li graf-after--li">MGGAN — <a href="https://arxiv.org/abs/1804.04391" data-href="https://arxiv.org/abs/1804.04391" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">MGGAN: Solving Mode Collapse using Manifold Guided Training</a></li><li name="9870" id="9870" class="graf graf--li graf-after--li">MIL-GAN — <a href="https://arxiv.org/abs/1712.01455" data-href="https://arxiv.org/abs/1712.01455" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Multimodal Storytelling via Generative Adversarial Imitation Learning</a></li><li name="8747" id="8747" class="graf graf--li graf-after--li">MIX+GAN — <a href="https://arxiv.org/abs/1703.00573v3" data-href="https://arxiv.org/abs/1703.00573v3" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Generalization and Equilibrium in Generative Adversarial Nets (GANs)</a></li><li name="c2ba" id="c2ba" class="graf graf--li graf-after--li">MLGAN — <a href="https://arxiv.org/abs/1711.02792" data-href="https://arxiv.org/abs/1711.02792" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Metric Learning-based Generative Adversarial Network</a></li><li name="0d84" id="0d84" class="graf graf--li graf-after--li">MMD-GAN — <a href="https://arxiv.org/abs/1705.08584" data-href="https://arxiv.org/abs/1705.08584" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">MMD GAN: Towards Deeper Understanding of Moment Matching Network</a> (<a href="https://github.com/dougalsutherland/opt-mmd" data-href="https://github.com/dougalsutherland/opt-mmd" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">github</a>)</li><li name="0540" id="0540" class="graf graf--li graf-after--li">MMGAN — <a href="https://arxiv.org/abs/1707.08273" data-href="https://arxiv.org/abs/1707.08273" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">MMGAN: Manifold Matching Generative Adversarial Network for Generating Images</a></li><li name="0cdf" id="0cdf" class="graf graf--li graf-after--li">MoCoGAN — <a href="https://arxiv.org/abs/1707.04993" data-href="https://arxiv.org/abs/1707.04993" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">MoCoGAN: Decomposing Motion and Content for Video Generation</a> (<a href="https://github.com/sergeytulyakov/mocogan" data-href="https://github.com/sergeytulyakov/mocogan" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">github</a>)</li><li name="e486" id="e486" class="graf graf--li graf-after--li">ModularGAN — <a href="https://arxiv.org/abs/1804.03343" data-href="https://arxiv.org/abs/1804.03343" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Modular Generative Adversarial Networks</a></li><li name="2183" id="2183" class="graf graf--li graf-after--li">MPM-GAN — <a href="https://arxiv.org/abs/1612.01294" data-href="https://arxiv.org/abs/1612.01294" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Message Passing Multi-Agent GANs</a></li><li name="61bf" id="61bf" class="graf graf--li graf-after--li">MS-GAN — <a href="http://papers.nips.cc/paper/7014-temporal-coherency-based-criteria-for-predicting-video-frames-using-deep-multi-stage-generative-adversarial-networks" data-href="http://papers.nips.cc/paper/7014-temporal-coherency-based-criteria-for-predicting-video-frames-using-deep-multi-stage-generative-adversarial-networks" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Temporal Coherency based Criteria for Predicting Video Frames using Deep Multi-stage Generative Adversarial Networks</a></li><li name="44c9" id="44c9" class="graf graf--li graf-after--li">MTGAN — <a href="https://arxiv.org/abs/1803.09059" data-href="https://arxiv.org/abs/1803.09059" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">MTGAN: Speaker Verification through Multitasking Triplet Generative Adversarial Networks</a></li><li name="a5a9" id="a5a9" class="graf graf--li graf-after--li">MuseGAN — <a href="https://arxiv.org/abs/1709.06298" data-href="https://arxiv.org/abs/1709.06298" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">MuseGAN: Symbolic-domain Music Generation and Accompaniment with Multi-track Sequential Generative Adversarial Networks</a></li><li name="23d1" id="23d1" class="graf graf--li graf-after--li">MV-BiGAN — <a href="https://arxiv.org/abs/1611.02019v1" data-href="https://arxiv.org/abs/1611.02019v1" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Multi-view Generative Adversarial Networks</a></li><li name="4355" id="4355" class="graf graf--li graf-after--li">NAN — <a href="https://arxiv.org/abs/1804.03287" data-href="https://arxiv.org/abs/1804.03287" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Understanding Humans in Crowded Scenes: Deep Nested Adversarial Learning and A New Benchmark for Multi-Human Parsing</a></li><li name="43ac" id="43ac" class="graf graf--li graf-after--li">NCE-GAN — <a href="https://arxiv.org/abs/1803.10996" data-href="https://arxiv.org/abs/1803.10996" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Dihedral angle prediction using generative adversarial networks</a></li><li name="c2b8" id="c2b8" class="graf graf--li graf-after--li">ND-GAN — <a href="https://arxiv.org/abs/1802.10560" data-href="https://arxiv.org/abs/1802.10560" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Novelty Detection with GAN</a></li><li name="8ad9" id="8ad9" class="graf graf--li graf-after--li">NetGAN — <a href="https://arxiv.org/abs/1803.00816" data-href="https://arxiv.org/abs/1803.00816" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">NetGAN: Generating Graphs via Random Walks</a></li><li name="9c63" id="9c63" class="graf graf--li graf-after--li">OCAN — <a href="https://arxiv.org/abs/1803.01798" data-href="https://arxiv.org/abs/1803.01798" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">One-Class Adversarial Nets for Fraud Detection</a></li><li name="a367" id="a367" class="graf graf--li graf-after--li">OptionGAN — <a href="https://arxiv.org/abs/1709.06683" data-href="https://arxiv.org/abs/1709.06683" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">OptionGAN: Learning Joint Reward-Policy Options using Generative Adversarial Inverse Reinforcement Learning</a></li><li name="6056" id="6056" class="graf graf--li graf-after--li">ORGAN — <a href="https://arxiv.org/abs/1705.10843" data-href="https://arxiv.org/abs/1705.10843" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Objective-Reinforced Generative Adversarial Networks (ORGAN) for Sequence Generation Models</a></li><li name="1377" id="1377" class="graf graf--li graf-after--li">ORGAN — <a href="https://arxiv.org/abs/1711.06363" data-href="https://arxiv.org/abs/1711.06363" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">3D Reconstruction of Incomplete Archaeological Objects Using a Generative Adversary Network</a></li><li name="f026" id="f026" class="graf graf--li graf-after--li">OT-GAN — <a href="https://arxiv.org/abs/1803.05573" data-href="https://arxiv.org/abs/1803.05573" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Improving GANs Using Optimal Transport</a></li><li name="ef84" id="ef84" class="graf graf--li graf-after--li">PacGAN — <a href="https://arxiv.org/abs/1712.04086" data-href="https://arxiv.org/abs/1712.04086" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">PacGAN: The power of two samples in generative adversarial networks</a></li><li name="ce3a" id="ce3a" class="graf graf--li graf-after--li">PAN — <a href="https://arxiv.org/abs/1706.09138" data-href="https://arxiv.org/abs/1706.09138" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Perceptual Adversarial Networks for Image-to-Image Transformation</a></li><li name="dfc8" id="dfc8" class="graf graf--li graf-after--li">PassGAN — <a href="https://arxiv.org/abs/1709.00440" data-href="https://arxiv.org/abs/1709.00440" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">PassGAN: A Deep Learning Approach for Password Guessing</a></li><li name="3234" id="3234" class="graf graf--li graf-after--li">Perceptual GAN — <a href="https://arxiv.org/abs/1706.05274" data-href="https://arxiv.org/abs/1706.05274" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Perceptual Generative Adversarial Networks for Small Object Detection</a></li><li name="f37a" id="f37a" class="graf graf--li graf-after--li">PGAN — <a href="https://arxiv.org/abs/1708.01886" data-href="https://arxiv.org/abs/1708.01886" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Probabilistic Generative Adversarial Networks</a></li><li name="a267" id="a267" class="graf graf--li graf-after--li">PGD-GAN — <a href="https://arxiv.org/abs/1802.08406" data-href="https://arxiv.org/abs/1802.08406" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Solving Linear Inverse Problems Using GAN Priors: An Algorithm with Provable Guarantees</a></li><li name="e5ef" id="e5ef" class="graf graf--li graf-after--li">PGGAN — <a href="https://arxiv.org/abs/1803.07422" data-href="https://arxiv.org/abs/1803.07422" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Patch-Based Image Inpainting with Generative Adversarial Networks</a></li><li name="eeed" id="eeed" class="graf graf--li graf-after--li">Pip-GAN — <a href="https://arxiv.org/abs/1711.10742" data-href="https://arxiv.org/abs/1711.10742" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Pipeline Generative Adversarial Networks for Facial Images Generation with Multiple Attributes</a></li><li name="1082" id="1082" class="graf graf--li graf-after--li">pix2pix — <a href="https://arxiv.org/abs/1611.07004" data-href="https://arxiv.org/abs/1611.07004" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Image-to-Image Translation with Conditional Adversarial Networks</a> (<a href="https://github.com/phillipi/pix2pix" data-href="https://github.com/phillipi/pix2pix" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">github</a>)</li><li name="5a3a" id="5a3a" class="graf graf--li graf-after--li">pix2pixHD — <a href="https://arxiv.org/abs/1711.11585" data-href="https://arxiv.org/abs/1711.11585" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">High-Resolution Image Synthesis and Semantic Manipulation with Conditional GANs</a> (<a href="https://github.com/NVIDIA/pix2pixHD" data-href="https://github.com/NVIDIA/pix2pixHD" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">github</a>)</li><li name="9222" id="9222" class="graf graf--li graf-after--li">PixelGAN — <a href="https://arxiv.org/abs/1706.00531" data-href="https://arxiv.org/abs/1706.00531" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">PixelGAN Autoencoders</a></li><li name="5726" id="5726" class="graf graf--li graf-after--li">PN-GAN — <a href="https://arxiv.org/abs/1712.02225" data-href="https://arxiv.org/abs/1712.02225" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Pose-Normalized Image Generation for Person Re-identification</a></li><li name="44cc" id="44cc" class="graf graf--li graf-after--li">Pose-GAN — <a href="https://arxiv.org/abs/1705.00053" data-href="https://arxiv.org/abs/1705.00053" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">The Pose Knows: Video Forecasting by Generating Pose Futures</a></li><li name="a6f9" id="a6f9" class="graf graf--li graf-after--li">PPAN — <a href="https://arxiv.org/abs/1712.07008" data-href="https://arxiv.org/abs/1712.07008" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Privacy-Preserving Adversarial Networks</a></li><li name="081c" id="081c" class="graf graf--li graf-after--li">PPGN — <a href="https://arxiv.org/abs/1612.00005" data-href="https://arxiv.org/abs/1612.00005" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Plug &amp; Play Generative Networks: Conditional Iterative Generation of Images in Latent Space</a></li><li name="42e7" id="42e7" class="graf graf--li graf-after--li">PrGAN — <a href="https://arxiv.org/abs/1612.05872" data-href="https://arxiv.org/abs/1612.05872" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">3D Shape Induction from 2D Views of Multiple Objects</a></li><li name="4320" id="4320" class="graf graf--li graf-after--li">ProGanSR — <a href="https://arxiv.org/abs/1804.02900" data-href="https://arxiv.org/abs/1804.02900" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">A Fully Progressive Approach to Single-Image Super-Resolution</a></li><li name="feff" id="feff" class="graf graf--li graf-after--li">Progressive GAN — <a href="https://arxiv.org/abs/1710.10196" data-href="https://arxiv.org/abs/1710.10196" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Progressive Growing of GANs for Improved Quality, Stability, and Variation</a> (<a href="https://github.com/tkarras/progressive_growing_of_gans" data-href="https://github.com/tkarras/progressive_growing_of_gans" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">github</a>)</li><li name="e762" id="e762" class="graf graf--li graf-after--li">PS-GAN — <a href="https://arxiv.org/abs/1804.02047" data-href="https://arxiv.org/abs/1804.02047" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Pedestrian-Synthesis-GAN: Generating Pedestrian Data in Real Scene and Beyond</a></li><li name="6c97" id="6c97" class="graf graf--li graf-after--li">PSGAN — <a href="http://arxiv.org/abs/1705.06566" data-href="http://arxiv.org/abs/1705.06566" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Learning Texture Manifolds with the Periodic Spatial GAN</a></li><li name="f5e8" id="f5e8" class="graf graf--li graf-after--li">PS²-GAN — <a href="https://arxiv.org/abs/1710.10182" data-href="https://arxiv.org/abs/1710.10182" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">High-Quality Facial Photo-Sketch Synthesis Using Multi-Adversarial Networks</a></li><li name="9b7f" id="9b7f" class="graf graf--li graf-after--li">RadialGAN — <a href="http://arxiv.org/abs/1802.06403" data-href="http://arxiv.org/abs/1802.06403" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">RadialGAN: Leveraging multiple datasets to improve target-specific predictive models using Generative Adversarial Networks</a></li><li name="e56c" id="e56c" class="graf graf--li graf-after--li">RAN — <a href="https://arxiv.org/abs/1712.05444" data-href="https://arxiv.org/abs/1712.05444" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">RAN4IQA: Restorative Adversarial Nets for No-Reference Image Quality Assessment</a> (<a href="https://github.com/hindupuravinash/the-gan-zoo/blob/master" data-href="https://github.com/hindupuravinash/the-gan-zoo/blob/master" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">github</a>)</li><li name="8abb" id="8abb" class="graf graf--li graf-after--li">RankGAN — <a href="https://arxiv.org/abs/1705.11001" data-href="https://arxiv.org/abs/1705.11001" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Adversarial Ranking for Language Generation</a></li><li name="9189" id="9189" class="graf graf--li graf-after--li">RCGAN — <a href="https://arxiv.org/abs/1706.02633" data-href="https://arxiv.org/abs/1706.02633" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Real-valued (Medical) Time Series Generation with Recurrent Conditional GANs</a></li><li name="0647" id="0647" class="graf graf--li graf-after--li">RefineGAN — <a href="https://arxiv.org/abs/1709.00753" data-href="https://arxiv.org/abs/1709.00753" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Compressed Sensing MRI Reconstruction with Cyclic Loss in Generative Adversarial Networks</a></li><li name="c717" id="c717" class="graf graf--li graf-after--li">RenderGAN — <a href="https://arxiv.org/abs/1611.01331" data-href="https://arxiv.org/abs/1611.01331" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">RenderGAN: Generating Realistic Labeled Data</a></li><li name="a8de" id="a8de" class="graf graf--li graf-after--li">ResGAN — <a href="https://arxiv.org/abs/1707.04881" data-href="https://arxiv.org/abs/1707.04881" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Generative Adversarial Network based on Resnet for Conditional Image Restoration</a></li><li name="7759" id="7759" class="graf graf--li graf-after--li">RNN-WGAN — <a href="https://arxiv.org/abs/1706.01399" data-href="https://arxiv.org/abs/1706.01399" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Language Generation with Recurrent Generative Adversarial Networks without Pre-training</a> (<a href="https://github.com/amirbar/rnn.wgan" data-href="https://github.com/amirbar/rnn.wgan" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">github</a>)</li><li name="dfe5" id="dfe5" class="graf graf--li graf-after--li">RPGAN — <a href="https://arxiv.org/abs/1705.07831" data-href="https://arxiv.org/abs/1705.07831" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Stabilizing GAN Training with Multiple Random Projections</a> (<a href="https://github.com/ayanc/rpgan" data-href="https://github.com/ayanc/rpgan" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">github</a>)</li><li name="a823" id="a823" class="graf graf--li graf-after--li">RTT-GAN — <a href="https://arxiv.org/abs/1703.07022v2" data-href="https://arxiv.org/abs/1703.07022v2" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Recurrent Topic-Transition GAN for Visual Paragraph Generation</a></li><li name="d1bb" id="d1bb" class="graf graf--li graf-after--li">RWGAN — <a href="https://arxiv.org/abs/1705.07164" data-href="https://arxiv.org/abs/1705.07164" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Relaxed Wasserstein with Applications to GANs</a></li><li name="0a65" id="0a65" class="graf graf--li graf-after--li">SAD-GAN — <a href="https://arxiv.org/abs/1611.08788v1" data-href="https://arxiv.org/abs/1611.08788v1" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">SAD-GAN: Synthetic Autonomous Driving using Generative Adversarial Networks</a></li><li name="5202" id="5202" class="graf graf--li graf-after--li">SAGA — <a href="https://arxiv.org/abs/1804.00709" data-href="https://arxiv.org/abs/1804.00709" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Generative Adversarial Learning for Spectrum Sensing</a></li><li name="b81b" id="b81b" class="graf graf--li graf-after--li">SalGAN — <a href="https://arxiv.org/abs/1701.01081" data-href="https://arxiv.org/abs/1701.01081" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">SalGAN: Visual Saliency Prediction with Generative Adversarial Networks</a> (<a href="https://github.com/imatge-upc/saliency-salgan-2017" data-href="https://github.com/imatge-upc/saliency-salgan-2017" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">github</a>)</li><li name="c638" id="c638" class="graf graf--li graf-after--li">SAR-GAN — <a href="https://arxiv.org/abs/1802.10036" data-href="https://arxiv.org/abs/1802.10036" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Generating High Quality Visible Images from SAR Images Using CNNs</a></li><li name="5218" id="5218" class="graf graf--li graf-after--li">SBADA-GAN — <a href="https://arxiv.org/abs/1705.08824" data-href="https://arxiv.org/abs/1705.08824" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">From source to target and back: symmetric bi-directional adaptive GAN</a></li><li name="ccb1" id="ccb1" class="graf graf--li graf-after--li">SCH-GAN — <a href="https://arxiv.org/abs/1802.02488" data-href="https://arxiv.org/abs/1802.02488" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">SCH-GAN: Semi-supervised Cross-modal Hashing by Generative Adversarial Network</a></li><li name="b77e" id="b77e" class="graf graf--li graf-after--li">SD-GAN — <a href="https://arxiv.org/abs/1705.07904" data-href="https://arxiv.org/abs/1705.07904" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Semantically Decomposing the Latent Spaces of Generative Adversarial Networks</a></li><li name="6630" id="6630" class="graf graf--li graf-after--li">Sdf-GAN — <a href="https://arxiv.org/abs/1803.06657" data-href="https://arxiv.org/abs/1803.06657" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Sdf-GAN: Semi-supervised Depth Fusion with Multi-scale Adversarial Networks</a></li><li name="182f" id="182f" class="graf graf--li graf-after--li">SEGAN — <a href="https://arxiv.org/abs/1703.09452v1" data-href="https://arxiv.org/abs/1703.09452v1" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">SEGAN: Speech Enhancement Generative Adversarial Network</a></li><li name="c845" id="c845" class="graf graf--li graf-after--li">SeGAN — <a href="https://arxiv.org/abs/1703.10239" data-href="https://arxiv.org/abs/1703.10239" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">SeGAN: Segmenting and Generating the Invisible</a></li><li name="e6aa" id="e6aa" class="graf graf--li graf-after--li">SegAN — <a href="https://arxiv.org/abs/1706.01805" data-href="https://arxiv.org/abs/1706.01805" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">SegAN: Adversarial Network with Multi-scale L1 Loss for Medical Image Segmentation</a></li><li name="5637" id="5637" class="graf graf--li graf-after--li">SeqGAN — <a href="https://arxiv.org/abs/1609.05473v5" data-href="https://arxiv.org/abs/1609.05473v5" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">SeqGAN: Sequence Generative Adversarial Nets with Policy Gradient</a> (<a href="https://github.com/LantaoYu/SeqGAN" data-href="https://github.com/LantaoYu/SeqGAN" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">github</a>)</li><li name="53ec" id="53ec" class="graf graf--li graf-after--li">SG-GAN — <a href="https://arxiv.org/abs/1801.01726" data-href="https://arxiv.org/abs/1801.01726" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Semantic-aware Grad-GAN for Virtual-to-Real Urban Scene Adaption</a> (<a href="https://github.com/Peilun-Li/SG-GAN" data-href="https://github.com/Peilun-Li/SG-GAN" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">github</a>)</li><li name="e078" id="e078" class="graf graf--li graf-after--li">SGAN — <a href="https://arxiv.org/abs/1611.08207" data-href="https://arxiv.org/abs/1611.08207" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Texture Synthesis with Spatial Generative Adversarial Networks</a></li><li name="a99e" id="a99e" class="graf graf--li graf-after--li">SGAN — <a href="https://arxiv.org/abs/1612.04357v4" data-href="https://arxiv.org/abs/1612.04357v4" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Stacked Generative Adversarial Networks</a> (<a href="https://github.com/xunhuang1995/SGAN" data-href="https://github.com/xunhuang1995/SGAN" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">github</a>)</li><li name="6b18" id="6b18" class="graf graf--li graf-after--li">SGAN — <a href="https://arxiv.org/abs/1703.05502" data-href="https://arxiv.org/abs/1703.05502" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Steganographic Generative Adversarial Networks</a></li><li name="9230" id="9230" class="graf graf--li graf-after--li">SGAN — <a href="https://arxiv.org/abs/1712.02330" data-href="https://arxiv.org/abs/1712.02330" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">SGAN: An Alternative Training of Generative Adversarial Networks</a></li><li name="98b0" id="98b0" class="graf graf--li graf-after--li">sGAN — <a href="https://arxiv.org/abs/1804.04366" data-href="https://arxiv.org/abs/1804.04366" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Generative Adversarial Training for MRA Image Synthesis Using Multi-Contrast MRI</a></li><li name="565c" id="565c" class="graf graf--li graf-after--li">SimGAN — <a href="https://arxiv.org/abs/1612.07828" data-href="https://arxiv.org/abs/1612.07828" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Learning from Simulated and Unsupervised Images through Adversarial Training</a></li><li name="4e93" id="4e93" class="graf graf--li graf-after--li">SisGAN — <a href="https://arxiv.org/abs/1707.06873" data-href="https://arxiv.org/abs/1707.06873" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Semantic Image Synthesis via Adversarial Learning</a></li><li name="2a96" id="2a96" class="graf graf--li graf-after--li">SketchGAN — <a href="https://arxiv.org/abs/1607.02748" data-href="https://arxiv.org/abs/1607.02748" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Adversarial Training For Sketch Retrieval</a></li><li name="83a9" id="83a9" class="graf graf--li graf-after--li">SketchyGAN — <a href="https://arxiv.org/abs/1801.02753" data-href="https://arxiv.org/abs/1801.02753" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">SketchyGAN: Towards Diverse and Realistic Sketch to Image Synthesis</a></li><li name="de25" id="de25" class="graf graf--li graf-after--li">SL-GAN — <a href="https://arxiv.org/abs/1704.02166" data-href="https://arxiv.org/abs/1704.02166" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Semi-Latent GAN: Learning to generate and modify facial images from attributes</a></li><li name="60fb" id="60fb" class="graf graf--li graf-after--li">SN-GAN — <a href="https://drive.google.com/file/d/0B8HZ50DPgR3eSVV6YlF3XzQxSjQ/view" data-href="https://drive.google.com/file/d/0B8HZ50DPgR3eSVV6YlF3XzQxSjQ/view" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Spectral Normalization for Generative Adversarial Networks</a> (<a href="https://github.com/pfnet-research/chainer-gan-lib" data-href="https://github.com/pfnet-research/chainer-gan-lib" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">github</a>)</li><li name="bf42" id="bf42" class="graf graf--li graf-after--li">Sobolev GAN — <a href="https://arxiv.org/abs/1711.04894" data-href="https://arxiv.org/abs/1711.04894" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Sobolev GAN</a></li><li name="7119" id="7119" class="graf graf--li graf-after--li">Social GAN — <a href="https://arxiv.org/abs/1803.10892" data-href="https://arxiv.org/abs/1803.10892" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Social GAN: Socially Acceptable Trajectories with Generative Adversarial Networks</a></li><li name="3093" id="3093" class="graf graf--li graf-after--li">Softmax GAN — <a href="https://arxiv.org/abs/1704.06191" data-href="https://arxiv.org/abs/1704.06191" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Softmax GAN</a></li><li name="fe08" id="fe08" class="graf graf--li graf-after--li">Spike-GAN — <a href="https://arxiv.org/abs/1803.00338" data-href="https://arxiv.org/abs/1803.00338" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Synthesizing realistic neural population activity patterns using Generative Adversarial Networks</a></li><li name="f2bc" id="f2bc" class="graf graf--li graf-after--li">Splitting GAN — <a href="https://arxiv.org/abs/1709.07359" data-href="https://arxiv.org/abs/1709.07359" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Class-Splitting Generative Adversarial Networks</a></li><li name="aae3" id="aae3" class="graf graf--li graf-after--li">SRGAN — <a href="https://arxiv.org/abs/1609.04802" data-href="https://arxiv.org/abs/1609.04802" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network</a></li><li name="0788" id="0788" class="graf graf--li graf-after--li">SRPGAN — <a href="https://arxiv.org/abs/1712.05927" data-href="https://arxiv.org/abs/1712.05927" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">SRPGAN: Perceptual Generative Adversarial Network for Single Image Super Resolution</a></li><li name="3166" id="3166" class="graf graf--li graf-after--li">SS-GAN — <a href="https://arxiv.org/abs/1708.05789" data-href="https://arxiv.org/abs/1708.05789" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Semi-supervised Conditional GANs</a></li><li name="f808" id="f808" class="graf graf--li graf-after--li">ss-InfoGAN — <a href="https://arxiv.org/abs/1707.04487" data-href="https://arxiv.org/abs/1707.04487" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Guiding InfoGAN with Semi-Supervision</a></li><li name="61b2" id="61b2" class="graf graf--li graf-after--li">SSGAN — <a href="https://arxiv.org/abs/1707.01613" data-href="https://arxiv.org/abs/1707.01613" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">SSGAN: Secure Steganography Based on Generative Adversarial Networks</a></li><li name="6362" id="6362" class="graf graf--li graf-after--li">SSL-GAN — <a href="https://arxiv.org/abs/1611.06430v1" data-href="https://arxiv.org/abs/1611.06430v1" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Semi-Supervised Learning with Context-Conditional Generative Adversarial Networks</a></li><li name="4bdf" id="4bdf" class="graf graf--li graf-after--li">ST-CGAN — <a href="https://arxiv.org/abs/1712.02478" data-href="https://arxiv.org/abs/1712.02478" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Stacked Conditional Generative Adversarial Networks for Jointly Learning Shadow Detection and Shadow Removal</a></li><li name="65b5" id="65b5" class="graf graf--li graf-after--li">ST-GAN — <a href="https://arxiv.org/abs/1702.06762" data-href="https://arxiv.org/abs/1702.06762" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Style Transfer Generative Adversarial Networks: Learning to Play Chess Differently</a></li><li name="72c1" id="72c1" class="graf graf--li graf-after--li">ST-GAN — <a href="https://arxiv.org/abs/1803.01837" data-href="https://arxiv.org/abs/1803.01837" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">ST-GAN: Spatial Transformer Generative Adversarial Networks for Image Compositing</a></li><li name="2408" id="2408" class="graf graf--li graf-after--li">StackGAN — <a href="https://arxiv.org/abs/1612.03242v1" data-href="https://arxiv.org/abs/1612.03242v1" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">StackGAN: Text to Photo-realistic Image Synthesis with Stacked Generative Adversarial Networks</a></li><li name="3170" id="3170" class="graf graf--li graf-after--li">StarGAN — <a href="https://arxiv.org/abs/1711.09020" data-href="https://arxiv.org/abs/1711.09020" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">StarGAN: Unified Generative Adversarial Networks for Multi-Domain Image-to-Image Translation</a> (<a href="https://github.com/yunjey/StarGAN" data-href="https://github.com/yunjey/StarGAN" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">github</a>)</li><li name="5d95" id="5d95" class="graf graf--li graf-after--li">SteinGAN — <a href="https://arxiv.org/abs/1707.00797" data-href="https://arxiv.org/abs/1707.00797" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Learning Deep Energy Models: Contrastive Divergence vs. Amortized MLE</a></li><li name="aae6" id="aae6" class="graf graf--li graf-after--li">Super-FAN — <a href="https://arxiv.org/abs/1712.02765" data-href="https://arxiv.org/abs/1712.02765" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Super-FAN: Integrated facial landmark localization and super-resolution of real-world low resolution faces in arbitrary poses with GANs</a></li><li name="8ecb" id="8ecb" class="graf graf--li graf-after--li">SVSGAN — <a href="https://arxiv.org/abs/1710.11428" data-href="https://arxiv.org/abs/1710.11428" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">SVSGAN: Singing Voice Separation via Generative Adversarial Network</a></li><li name="54b4" id="54b4" class="graf graf--li graf-after--li">SWGAN — <a href="https://arxiv.org/abs/1802.08249" data-href="https://arxiv.org/abs/1802.08249" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Solving Approximate Wasserstein GANs to Stationarity</a></li><li name="7ebd" id="7ebd" class="graf graf--li graf-after--li">SyncGAN — <a href="https://arxiv.org/abs/1804.00410" data-href="https://arxiv.org/abs/1804.00410" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">SyncGAN: Synchronize the Latent Space of Cross-modal Generative Adversarial Networks</a></li><li name="5413" id="5413" class="graf graf--li graf-after--li">S²GAN — <a href="https://arxiv.org/abs/1603.05631v2" data-href="https://arxiv.org/abs/1603.05631v2" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Generative Image Modeling using Style and Structure Adversarial Networks</a></li><li name="0b02" id="0b02" class="graf graf--li graf-after--li">TAC-GAN — <a href="https://arxiv.org/abs/1703.06412v2" data-href="https://arxiv.org/abs/1703.06412v2" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">TAC-GAN — Text Conditioned Auxiliary Classifier Generative Adversarial Network</a> (<a href="https://github.com/dashayushman/TAC-GAN" data-href="https://github.com/dashayushman/TAC-GAN" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">github</a>)</li><li name="f2bd" id="f2bd" class="graf graf--li graf-after--li">TAN — <a href="https://arxiv.org/abs/1704.08834" data-href="https://arxiv.org/abs/1704.08834" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Outline Colorization through Tandem Adversarial Networks</a></li><li name="fc78" id="fc78" class="graf graf--li graf-after--li">tempoGAN — <a href="https://arxiv.org/abs/1801.09710" data-href="https://arxiv.org/abs/1801.09710" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">tempoGAN: A Temporally Coherent, Volumetric GAN for Super-resolution Fluid Flow</a></li><li name="b5a3" id="b5a3" class="graf graf--li graf-after--li">Text2Shape — <a href="https://arxiv.org/abs/1803.08495" data-href="https://arxiv.org/abs/1803.08495" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Text2Shape: Generating Shapes from Natural Language by Learning Joint Embeddings</a></li><li name="2b09" id="2b09" class="graf graf--li graf-after--li">textGAN — <a href="https://zhegan27.github.io/Papers/textGAN_nips2016_workshop.pdf" data-href="https://zhegan27.github.io/Papers/textGAN_nips2016_workshop.pdf" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Generating Text via Adversarial Training</a></li><li name="f764" id="f764" class="graf graf--li graf-after--li">TextureGAN — <a href="https://arxiv.org/abs/1706.02823" data-href="https://arxiv.org/abs/1706.02823" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">TextureGAN: Controlling Deep Image Synthesis with Texture Patches</a></li><li name="8db8" id="8db8" class="graf graf--li graf-after--li">TGAN — <a href="https://arxiv.org/abs/1611.06624v1" data-href="https://arxiv.org/abs/1611.06624v1" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Temporal Generative Adversarial Nets</a></li><li name="2a95" id="2a95" class="graf graf--li graf-after--li">TGAN — <a href="https://arxiv.org/abs/1710.10772" data-href="https://arxiv.org/abs/1710.10772" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Tensorizing Generative Adversarial Nets</a></li><li name="5e26" id="5e26" class="graf graf--li graf-after--li">TGAN — <a href="https://arxiv.org/abs/1711.02666" data-href="https://arxiv.org/abs/1711.02666" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Tensor-Generative Adversarial Network with Two-dimensional Sparse Coding: Application to Real-time Indoor Localization</a></li><li name="7141" id="7141" class="graf graf--li graf-after--li">tiny-GAN — <a href="https://arxiv.org/abs/1803.05045" data-href="https://arxiv.org/abs/1803.05045" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Analysis of Nonautonomous Adversarial Systems</a></li><li name="8ced" id="8ced" class="graf graf--li graf-after--li">TP-GAN — <a href="https://arxiv.org/abs/1704.04086" data-href="https://arxiv.org/abs/1704.04086" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Beyond Face Rotation: Global and Local Perception GAN for Photorealistic and Identity Preserving Frontal View Synthesis</a></li><li name="7889" id="7889" class="graf graf--li graf-after--li">Triple-GAN — <a href="https://arxiv.org/abs/1703.02291v2" data-href="https://arxiv.org/abs/1703.02291v2" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Triple Generative Adversarial Nets</a></li><li name="ed5c" id="ed5c" class="graf graf--li graf-after--li">tripletGAN — <a href="https://arxiv.org/abs/1711.05084" data-href="https://arxiv.org/abs/1711.05084" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">TripletGAN: Training Generative Model with Triplet Loss</a></li><li name="0d57" id="0d57" class="graf graf--li graf-after--li">TV-GAN — <a href="https://arxiv.org/abs/1712.02514" data-href="https://arxiv.org/abs/1712.02514" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">TV-GAN: Generative Adversarial Network Based Thermal to Visible Face Recognition</a></li><li name="20ac" id="20ac" class="graf graf--li graf-after--li">UGACH — <a href="https://arxiv.org/abs/1712.00358" data-href="https://arxiv.org/abs/1712.00358" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Unsupervised Generative Adversarial Cross-modal Hashing</a></li><li name="a70f" id="a70f" class="graf graf--li graf-after--li">UGAN — <a href="https://arxiv.org/abs/1801.04011" data-href="https://arxiv.org/abs/1801.04011" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Enhancing Underwater Imagery using Generative Adversarial Networks</a></li><li name="db4d" id="db4d" class="graf graf--li graf-after--li">Unim2im — <a href="https://arxiv.org/abs/1701.02676" data-href="https://arxiv.org/abs/1701.02676" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Unsupervised Image-to-Image Translation with Generative Adversarial Networks </a>(<a href="http://github.com/zsdonghao/Unsup-Im2Im" data-href="http://github.com/zsdonghao/Unsup-Im2Im" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">github</a>)</li><li name="fcbc" id="fcbc" class="graf graf--li graf-after--li">UNIT — <a href="https://arxiv.org/abs/1703.00848" data-href="https://arxiv.org/abs/1703.00848" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Unsupervised Image-to-image Translation Networks</a> (<a href="https://github.com/mingyuliutw/UNIT" data-href="https://github.com/mingyuliutw/UNIT" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">github</a>)</li><li name="f5a7" id="f5a7" class="graf graf--li graf-after--li">Unrolled GAN — <a href="https://arxiv.org/abs/1611.02163" data-href="https://arxiv.org/abs/1611.02163" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Unrolled Generative Adversarial Networks</a> (<a href="https://github.com/poolio/unrolled_gan" data-href="https://github.com/poolio/unrolled_gan" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">github</a>)</li><li name="73a6" id="73a6" class="graf graf--li graf-after--li">UV-GAN — <a href="https://arxiv.org/abs/1712.04695" data-href="https://arxiv.org/abs/1712.04695" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">UV-GAN: Adversarial Facial UV Map Completion for Pose-invariant Face Recognition</a></li><li name="c976" id="c976" class="graf graf--li graf-after--li">VAE-GAN — <a href="https://arxiv.org/abs/1512.09300" data-href="https://arxiv.org/abs/1512.09300" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Autoencoding beyond pixels using a learned similarity metric</a></li><li name="1f4b" id="1f4b" class="graf graf--li graf-after--li">VariGAN — <a href="https://arxiv.org/abs/1704.04886" data-href="https://arxiv.org/abs/1704.04886" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Multi-View Image Generation from a Single-View</a></li><li name="1584" id="1584" class="graf graf--li graf-after--li">VAW-GAN — <a href="https://arxiv.org/abs/1704.00849" data-href="https://arxiv.org/abs/1704.00849" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Voice Conversion from Unaligned Corpora using Variational Autoencoding Wasserstein Generative Adversarial Networks</a></li><li name="5a04" id="5a04" class="graf graf--li graf-after--li">VEEGAN — <a href="https://arxiv.org/abs/1705.07761" data-href="https://arxiv.org/abs/1705.07761" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">VEEGAN: Reducing Mode Collapse in GANs using Implicit Variational Learning</a> (<a href="https://github.com/akashgit/VEEGAN" data-href="https://github.com/akashgit/VEEGAN" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">github</a>)</li><li name="4965" id="4965" class="graf graf--li graf-after--li">VGAN — <a href="https://arxiv.org/abs/1609.02612" data-href="https://arxiv.org/abs/1609.02612" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Generating Videos with Scene Dynamics</a> (<a href="https://github.com/cvondrick/videogan" data-href="https://github.com/cvondrick/videogan" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">github</a>)</li><li name="132d" id="132d" class="graf graf--li graf-after--li">VGAN — <a href="https://arxiv.org/abs/1611.01799" data-href="https://arxiv.org/abs/1611.01799" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Generative Adversarial Networks as Variational Training of Energy Based Models</a> (<a href="https://github.com/Shuangfei/vgan" data-href="https://github.com/Shuangfei/vgan" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">github</a>)</li><li name="0ea8" id="0ea8" class="graf graf--li graf-after--li">VGAN — <a href="https://arxiv.org/abs/1712.00170" data-href="https://arxiv.org/abs/1712.00170" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Text Generation Based on Generative Adversarial Nets with Latent Variable</a></li><li name="b9ed" id="b9ed" class="graf graf--li graf-after--li">ViGAN — <a href="https://arxiv.org/abs/1701.04568v1" data-href="https://arxiv.org/abs/1701.04568v1" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Image Generation and Editing with Variational Info Generative Adversarial Networks</a></li><li name="ba0a" id="ba0a" class="graf graf--li graf-after--li">VIGAN — <a href="https://arxiv.org/abs/1708.06724" data-href="https://arxiv.org/abs/1708.06724" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">VIGAN: Missing View Imputation with Generative Adversarial Networks</a></li><li name="276d" id="276d" class="graf graf--li graf-after--li">VoiceGAN — <a href="http://arxiv.org/abs/1802.06840" data-href="http://arxiv.org/abs/1802.06840" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Voice Impersonation using Generative Adversarial Networks</a></li><li name="2bef" id="2bef" class="graf graf--li graf-after--li">VOS-GAN — <a href="https://arxiv.org/abs/1803.09092" data-href="https://arxiv.org/abs/1803.09092" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">VOS-GAN: Adversarial Learning of Visual-Temporal Dynamics for Unsupervised Dense Prediction in Videos</a></li><li name="f2c3" id="f2c3" class="graf graf--li graf-after--li">VRAL — <a href="https://arxiv.org/abs/1707.00309" data-href="https://arxiv.org/abs/1707.00309" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Variance Regularizing Adversarial Learning</a></li><li name="a667" id="a667" class="graf graf--li graf-after--li">WaterGAN — <a href="https://arxiv.org/abs/1702.07392v1" data-href="https://arxiv.org/abs/1702.07392v1" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">WaterGAN: Unsupervised Generative Network to Enable Real-time Color Correction of Monocular Underwater Images</a></li><li name="0179" id="0179" class="graf graf--li graf-after--li">WaveGAN — <a href="https://arxiv.org/abs/1802.04208" data-href="https://arxiv.org/abs/1802.04208" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Synthesizing Audio with Generative Adversarial Networks</a></li><li name="d621" id="d621" class="graf graf--li graf-after--li">weGAN — <a href="https://arxiv.org/abs/1712.09127" data-href="https://arxiv.org/abs/1712.09127" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Generative Adversarial Nets for Multiple Text Corpora</a></li><li name="ff2b" id="ff2b" class="graf graf--li graf-after--li">WGAN — <a href="https://arxiv.org/abs/1701.07875v2" data-href="https://arxiv.org/abs/1701.07875v2" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Wasserstein GAN</a> (<a href="https://github.com/martinarjovsky/WassersteinGAN" data-href="https://github.com/martinarjovsky/WassersteinGAN" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">github</a>)</li><li name="ca4c" id="ca4c" class="graf graf--li graf-after--li">WGAN-GP — <a href="https://arxiv.org/abs/1704.00028" data-href="https://arxiv.org/abs/1704.00028" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Improved Training of Wasserstein GANs</a> (<a href="https://github.com/igul222/improved_wgan_training" data-href="https://github.com/igul222/improved_wgan_training" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">github</a>)</li><li name="d88a" id="d88a" class="graf graf--li graf-after--li">WS-GAN — <a href="https://arxiv.org/abs/1705.10904" data-href="https://arxiv.org/abs/1705.10904" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Weakly Supervised Generative Adversarial Networks for 3D Reconstruction</a></li><li name="7821" id="7821" class="graf graf--li graf-after--li">XGAN — <a href="https://arxiv.org/abs/1711.05139" data-href="https://arxiv.org/abs/1711.05139" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">XGAN: Unsupervised Image-to-Image Translation for many-to-many Mappings</a></li><li name="ee5e" id="ee5e" class="graf graf--li graf-after--li">ZipNet-GAN — <a href="https://arxiv.org/abs/1711.02413" data-href="https://arxiv.org/abs/1711.02413" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">ZipNet-GAN: Inferring Fine-grained Mobile Traffic Patterns via a Generative Adversarial Neural Network</a></li><li name="2536" id="2536" class="graf graf--li graf-after--li">α-GAN — <a href="https://arxiv.org/abs/1706.04987" data-href="https://arxiv.org/abs/1706.04987" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Variational Approaches for Auto-Encoding Generative Adversarial Networks</a> (<a href="https://github.com/victor-shepardson/alpha-GAN" data-href="https://github.com/victor-shepardson/alpha-GAN" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">github</a>)</li><li name="b036" id="b036" class="graf graf--li graf-after--li">β-GAN — <a href="https://arxiv.org/abs/1705.07505" data-href="https://arxiv.org/abs/1705.07505" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Annealed Generative Adversarial Networks</a></li><li name="8aae" id="8aae" class="graf graf--li graf-after--li">Δ-GAN — <a href="https://arxiv.org/abs/1709.06548" data-href="https://arxiv.org/abs/1709.06548" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Triangle Generative Adversarial Networks</a>

Visit the [Github
repository](https://github.com/hindupuravinash/the-gan-zoo) to add more links via pull requests or create an
issue to lemme know something I missed or to start a discussion. 

Thanks
to all the contributors, especially [Emanuele
Plebani](https://github.com/Banus),
[Lukas Galke](https://github.com/lgalke), [Peter
Waller](https://github.com/pwaller)
and [Bruno Gavranović](https://github.com/bgavran).


